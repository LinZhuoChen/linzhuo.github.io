---
title: Rethinking Atrous Convolution for Semantic Image Segmentation 笔记
categories:
- 计算机视觉
permalink: /posts/deeplabv3/
---

### Rethinking Atrous Convolution for Semantic Image Segmentation 笔记

原文链接：

[DeeplabV3]: https://arxiv.org/abs/1706.05587	"Rethinking Atrous Convolution for Semantic Image Segmentation"

### 1. Introduction

将神经网络运用到语义分割任务上有两大挑战：

1. 随连续的卷积和池化操作造成的特征分辨率降低：连续的卷积和池化有利于网络学习到更加抽象的特征表示。然而对于语义分割任务来说这样会损失很多细节。DeepLabV3 使用**atrous convolution** 来解决这个问题。

2. 物体存在多个尺度：有一些方法尝试解决这个问题，比如使用1. image pyramid , 2.encoder-decoder structure ,3.DenseCRF, 4.spatial pyramid pooling(PSP)等。

在这篇工作中，我们重新探索了atrous convolution，并在级联结构和并行结构(ASPP)上做了大量的实验。同时我们也讨论了当3*3的atrous convolution有着很大的rate时，具有的边界效应，以及对应的解决方法。

### 2. Method

#### 2.1 Atrous Convolution for Dense Feature Extraction 

这里简单回顾了下Atrous Convolution：其公式如下：
$$
y[i] = \sum_{k}x[i + r\times k]w[k],
$$
其中r为rate，在常规的卷积中r=1。

Atrous convolution 也可以控制最后输出特征图的分辨率。

#### 2.2 Going Deeper with Atrous Convolution 

我们首先使用串级结构来，我们将ResNet的block4复制几份，然后将它们用串联结构组织起来。stride对细节影响很大，因此我们用 Atrous Convolution 代替了stride。具体结构如下图所示：

![](/images/cascade.png)

##### 2.2.1 Multi-grid Method 

我们在block4-block7中使用不同的rate，最后的rate等于单位rate和corresponding rate 的乘积：举例来说：Multi-grid=[1,2,4], output_stride=16, 则最后的rate=2 * [1,2,4] = [2,4,8]。

#### 2.3 Atrous Spatial Pyramid Pooling 

我们使用了DeeplabV2中的ASPP架构，结构如下所示：我们可以看到这种架构有利于提取图像的多尺度特征。

![](/images/aspp.png)

我们发现随着rate的增大，有效的weight数目开始减少。为了解决这个问题，我们利用global average pooling提取了image-level的特征并与ASPP的特征并在一起，如上图所示。

### 3. Experimental Evaluation 

我们首先探究output stride与最终结果的关系：

![](images/output_stride.png)

可以看到 output_stride 越大，结果越差，这证明了保留空间尺寸的必要性。

接下来我们探究网络深度与结果的关系：

![](/images/deep_result.png)

可以看到随着网络的加深，结果越来越好，但是提升也越来越有限。

接下来我们探究Multi-grid对结果的影响：

![](images/multi-grid.png)

可以看到:

1. 使用multi-grid效果均好于(1,1,1)。

2. 简单的doubling unit rates 不是很有效。

3. 更深的网络和multi-grid会提升效果

接下来我们研究不同的验证策略对结果的影响（注意我们训练的时候output_stride为16）:

![](images/infer.png)

接下来我们验证ASPP在不同设置下的结果：

![](/images/aspp_result.png)

我们可以看到Multi-grid和Image pooling的效果，同时过大的增加delation会降低效果。

最后我们验证了在ASPP网络结构下不同的验证策略对结果的影响：

![](/images/infer2.png)

最后的实验结果如下所示：

![](images/result.png)

我认为deeplabv3效果很好主要有以下几点：一是在ASPP模块引入了batchnorm，二是引入了image pooling 来补充因为dilation丢失的信息。还有就是使用了更巧妙的训练测试手段。
